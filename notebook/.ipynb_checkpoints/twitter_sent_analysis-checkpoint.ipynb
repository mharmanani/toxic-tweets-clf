{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Natural Language Processing\n",
    "import nltk, re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['the', 'i', 'a'] # define different stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>it's unbelievable that in the 21st century we'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "17  18      1                             retweet if you agree! \n",
       "23  24      1    @user @user lumpy says i am a . prove it lumpy.\n",
       "34  35      1  it's unbelievable that in the 21st century we'..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['label'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hashtag(word : str) -> bool:\n",
    "    return word[0] == '#'\n",
    "def is_mention(word: str) -> bool:\n",
    "    return word[0] == '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet : str) -> str:\n",
    "    \"\"\" \n",
    "    Remove/replace mentions/hashtags with words.\n",
    "    \"\"\"\n",
    "    tokens = tweet.split()\n",
    "    for token in tokens:\n",
    "        token = token.strip()\n",
    "        if is_hashtag(token):\n",
    "            tweet=tweet.replace(token, token[1:])\n",
    "            #tweet=tweet.replace(token, '')\n",
    "        if is_mention(token):\n",
    "            tweet=tweet.replace(token, '')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(lambda text : ''.join([char for char in text if char not in string.punctuation]))\n",
    "df['tweet']=df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   user when a father is dysfunctional and is so...\n",
       "1   2      0  user user thanks for lyft credit i cant use ca...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  model   i love u take with u all the time in u...\n",
       "4   5      0               factsguide society now    motivation"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fda4fa90c90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(nltk.word_tokenize)\n",
    "df['tweet']=df['tweet'].apply(lambda x: list(filter(lambda y: not y in STOPWORDS, x)))\n",
    "df['tweet']=df['tweet'].apply(lambda x: list(filter(lambda y: y.isalpha(), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31934</th>\n",
       "      <td>31935</td>\n",
       "      <td>1</td>\n",
       "      <td>[lady, banned, from, kentucky, mall, user, jcp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>31947</td>\n",
       "      <td>1</td>\n",
       "      <td>[user, omfg, im, offended, im, mailbox, and, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>31948</td>\n",
       "      <td>1</td>\n",
       "      <td>[user, user, you, dont, have, balls, to, hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>31949</td>\n",
       "      <td>1</td>\n",
       "      <td>[makes, you, ask, yourself, who, am, then, am,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>[user, sikh, temple, vandalised, in, in, calga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "31934  31935      1  [lady, banned, from, kentucky, mall, user, jcp...\n",
       "31946  31947      1  [user, omfg, im, offended, im, mailbox, and, i...\n",
       "31947  31948      1  [user, user, you, dont, have, balls, to, hasht...\n",
       "31948  31949      1  [makes, you, ask, yourself, who, am, then, am,...\n",
       "31960  31961      1  [user, sikh, temple, vandalised, in, in, calga..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['label'] == 1].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Parts of Speech for Each Token\n",
    "def tag_parts_of_speech(token):\n",
    "    return nltk.pos_tag(nltk.word_tokenize(token))\n",
    "\n",
    "def pos_tagger(tokens):\n",
    "    ts = []\n",
    "    for word in tokens:\n",
    "        ts += tag_parts_of_speech(word)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(lambda xs: [lemmatizer.lemmatize(x) for x in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[user, when, father, is, dysfunctional, and, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, cant, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[model, love, u, take, with, u, all, time, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  [user, when, father, is, dysfunctional, and, i...\n",
       "1   2      0  [user, user, thanks, for, lyft, credit, cant, ...\n",
       "2   3      0                            [bihday, your, majesty]\n",
       "3   4      0     [model, love, u, take, with, u, all, time, in]\n",
       "4   5      0             [factsguide, society, now, motivation]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet=df.tweet.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Testing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_cv = CountVectorizer(binary=True, ngram_range=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.tweet\n",
    "y = np.array(df.label, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(3, 5), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ngram_cv.transform(X_train)\n",
    "X_val =  ngram_cv.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.075\n",
    "lr = LogisticRegression(C=c, solver='lbfgs')\n",
    "svm = LinearSVC(C=c)\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                   hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.fit( X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "nn.fit(X_train, y_train)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model):\n",
    "    count, total = 0, 0\n",
    "    for x in range(X_val.shape[0]):\n",
    "        pair = X_val[x], y_val[x]\n",
    "        if model.predict(pair[0]) == pair[1]:\n",
    "            count += 1\n",
    "        total += 1\n",
    "    print(round(100*count/total, 2), end='%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.92%"
     ]
    }
   ],
   "source": [
    "model_accuracy(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.09%"
     ]
    }
   ],
   "source": [
    "model_accuracy(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.65%"
     ]
    }
   ],
   "source": [
    "model_accuracy(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['orig_tweet']=df_test['tweet'].apply(lambda x: x)\n",
    "df_test['tweet']=df_test['tweet'].apply(clean_tweet)\n",
    "df_test['tweet']=df_test['tweet'].apply(nltk.word_tokenize)\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: list(filter(lambda y: not y in STOPWORDS, x)))\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: list(filter(lambda y: y.isalpha(), x)))\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda xs: [lemmatizer.lemmatize(x) for x in xs])\n",
    "df_test.tweet=df_test.tweet.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example = ngram_cv.transform(df_test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    for x in range(X_example.shape[0]):\n",
    "        i, p = df_test.tweet[x], model.predict(X_example[x])\n",
    "        if p:\n",
    "            print(i ,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message(model, message):\n",
    "    return model.predict(ngram_cv.transform(pd.DataFrame({'tweet': [message]}).tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test['tweet'].map(lambda tweet: 0)\n",
    "df_test['label'] = df_test['tweet'].map(lambda tweet: int(predict_message(svm, tweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = df_test[df_test.label == 1] # shows examples of tweets classified as toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thought factory: bbc neutrality on right wing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>hey @user - a $14000 ivanka bracelet? do you f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>@user all together this christmas: pls  &amp;amp; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>you might be a libtard if... #libtard  #sjw #l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>at work: attorneys for white officer who shot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17002</th>\n",
       "      <td>@user you are a complete jerk. your comments a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031</th>\n",
       "      <td>@user your comments are reflections of ignoran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17100</th>\n",
       "      <td>save the date! 1-4-2017 sourcenation! live wed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17128</th>\n",
       "      <td>@user the uk governmentâs new #anti-semitism...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              orig_tweet  label\n",
       "19     thought factory: bbc neutrality on right wing ...      1\n",
       "110    hey @user - a $14000 ivanka bracelet? do you f...      1\n",
       "140    @user all together this christmas: pls  &amp; ...      1\n",
       "141    you might be a libtard if... #libtard  #sjw #l...      1\n",
       "160     at work: attorneys for white officer who shot...      1\n",
       "...                                                  ...    ...\n",
       "17002  @user you are a complete jerk. your comments a...      1\n",
       "17031  @user your comments are reflections of ignoran...      1\n",
       "17100  save the date! 1-4-2017 sourcenation! live wed...      1\n",
       "17128  @user the uk governmentâs new #anti-semitism...      1\n",
       "17192  thought factory: left-right polarisation! #tru...      1\n",
       "\n",
       "[291 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones[['orig_tweet', 'label']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
